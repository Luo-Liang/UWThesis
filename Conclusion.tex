\chapter{Conclusion}
The surge of data volume and accelerator throughput demand new optimizations in communication to accelerate distributed learning. This paper argues deficiency in communication comes from hardware, software and the network infrastructure itself. Through co-designing of software and hardware and careful probing and exploiting of locality in the physical network, we demonstrate significant end-to-end training speedup can be obtained.